---
title: "Practical machine Learning"
author: "Sarah Shikangah"
date: "April 30, 2017"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Abstract

The main aim of this project is to predict the a behavior pattern labelled as "classe" variable from exercise activities. The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. The collected data from accelerometers on belt, forearm, arm, and dumbell of 6 participants will be used to perform machine learning project. Links to the datasets are; https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv, for training data set,;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv, for testing data set.

## Download required packages and data
We shall download packages required and data.
```{r data, echo = TRUE}
#Required packages
library(caret)
library(ggplot2)
library(lattice)
library(rattle)
library(rpart.plot)
library(randomForest)
library(MASS)
set.seed(12356)
PmlTraining <- read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", header = TRUE, sep = ",", dec = ".", na.strings=c("NA","#DIV/0!",""))
pmlTesting <-  read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", header = TRUE, sep = ",", dec = ".", na.strings=c("NA","#DIV/0!",""))
#str(PmlTraining) to check dataset
```
## Data cleaning
Processing data for analyses, by removing variables with missing data and character observations.

```{r data clean, echo=TRUE}
#Replace characters #DIV/0!with NA
tr <-  as.data.frame(sapply(PmlTraining,gsub,pattern="#DIV/0!",replacement="NA"))
test <- as.data.frame(sapply(pmlTesting,gsub,pattern="#DIV/0!",replacement="NA"))
# Remove variables with missing values
PmlTraining1 <-tr[,!sapply(tr,function(x) any(is.na(x)))]
pmlTesting <- test[,!sapply(test,function(x) any(is.na(x)))]
#Remove the first seven variables to avoid interferance .
Training1 <- PmlTraining1[,-c(1:7)]
Testing1 <- pmlTesting[, -c(1:7)]
#set all variables as numeric class with exception of classe variable
Training1[, 1:52] <- lapply(Training1[, 1:52], as.numeric)
Testing1[, 1:52] <- lapply(Testing1[, 1:52], as.numeric)
dim(Training1)
dim(Testing1)

```

## Splitting training dataset

```{r split data, echo= TRUE}
set.seed(12356)
inTrain <- createDataPartition(y=Training1$classe, p=0.75, list=FALSE)
training <- Training1[inTrain,]; validation <- Training1[-inTrain,]
dim(training);dim(validation)

```
## Exploratory analysis

```{r plots, echo=TRUE}
#Due to the space limited the plots will not be shown
# check covariance and corrilation using (cov(training[, 1:53]);cor(training[, 1:53]))
#featurePlot(x=Training1[, c(1:52)], y = Training1$classe, plot = "pairs")

```
## Fitting three different models.

we shall fit three different models and compare there accuracy and choose the best model for prediction on the testing data set. 
### Model 1 : Desicion tree
```{r model1, echo=TRUE}
set.seed(12356)
Fit <- train(classe~., method = "rpart", data = training)
fancyRpartPlot(Fit$finalModel)
```
### Model 2 : Random Forest
```{r, model 2, echo=TRUE}

fit2Rf <- randomForest(classe~.,data=training, ntree=200, importance=TRUE)
plot(fit2Rf)
```
### Model 3 : Linear Discriminant Analysis
```{r model 3, echo=TRUE}
Fitlda <- train(classe~., method = "lda", data = training)

```

## Predict on the testing set
```{r predict, echo= TRUE}
pred1 <- predict(Fit, validation)
pred2 <- predict(fit2Rf, validation)
pred3 <- predict(Fitlda, validation)
predDf <- data.frame(pred1, pred2, pred3, classe = validation$classe)
CombMod <- train(classe~., method = "rf", data = predDf)
pred4 <- predict(CombMod, predDf)


rbind(postResample(pred1, obs = validation$classe), postResample(pred2, obs = validation$classe), postResample(pred3, obs = validation$classe), postResample(pred4, obs = validation$classe))
AccuTest <- confusionMatrix(pred4, validation$classe)
AccuTest
```
From the above comparison result Random Forests model provided the best result with accuracy of 99.43%  which gives sample error to 0.57% and so as to the combined models. For this project we shall use Random Forests model to predict on the testing dataset.

## Predicting on the testing dataset
```{r predict test, echo = TRUE}
pred5T<- predict(fit2Rf, newdata = Testing1, type = "class")
pred5T

```
